{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Class\n",
    "**This notebook: [see on github](https://github.com/drinkingkazu/2019-06-17-NeuralNets/blob/master/Python%20Class%20and%20Iterable%20Dataset.ipynb) or [run it on google colab](https://colab.research.google.com/github/drinkingkazu/2019-06-17-Notebooks/blob/master/Python%20Class%20and%20Iteratable%20Dataset.ipynb)**.\n",
    "\n",
    "In case this audience hasn't practiced Python class, we start with a simple example of class _foo_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foo:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.A = 10\n",
    "    \n",
    "    def speak(self):\n",
    "        print('Hello world! A =',self.A)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'I am foo type instance object!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example class `foo` above have 3 implemented functions. Those starts with \"double-underscore\" (i.e. _init_ and _str_) are the **built-in functions** and we are over-riding the definitions. In particular, _str_ is responsible for providing a text representation of `foo` that is returned to `print` function call. \n",
    "\n",
    "You also notice that all functions starts with an argument _self_: that is equivalent of `this` pointer in C++. Class attribute functions require, in the definition, the first argument to be the caller's pointer. This is not an argument to be provided by the function caller. Below you see examples of how `foo` class instance may be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world! A = 10\n",
      "I am foo type instance object!\n"
     ]
    }
   ],
   "source": [
    "kazu = foo()\n",
    "kazu.speak()\n",
    "print(kazu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _ala C++ struct_: Attribute Holder\n",
    "In C++, for quick encapsulation, we often use a _struct_ container. A hacky but handy way of achieving something similar in Python is to define an empty class, and dyncamically attach attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLOB:\n",
    "    pass\n",
    "\n",
    "blob=BLOB()\n",
    "blob.data   = kazu\n",
    "blob.number = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can hand over a _blob_ object to/from functions and keep the arguments/return expression compact! Now, however, since this blob object is dynamic, you might want a capability to check, when given a blob object, a certain attribute exists or not. Python has a handy built-in functions `hasattr` and `getattr` (\"attr\" stands for \"attributes\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "I am foo type instance object!\n",
      "Hello world! A = 10\n"
     ]
    }
   ],
   "source": [
    "print( hasattr(blob, \"data\" ) )\n",
    "print( hasattr(blob, \"tracy\") )\n",
    "print( getattr(blob, \"data\" ) )\n",
    "getattr(blob, \"data\").speak()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteratable Dataset\n",
    "\n",
    "For training a network with Stochastic Gradient Decent (SGD), we need a method to stream a randomly selected subset of training data. The most common way is to form an _iteratable_ dataset with a random access capability. We practice to design such a Python class below. \n",
    "\n",
    "First, let's define a iterable container. For an iteration in Python, you need two built-in functions: a _len_ which returns the \"length of array-like data\" and _getitem_ which arrows a random-access operator (i.e. \"[ ]\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._data = range(100)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self._data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example class `dataset` constructs a simple data, an array of length 100 filled with numbers 0 to 99. The length of the dataset is accordingly 100, and the random access operator returns the corresponding index entry of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 100\n",
      "10th element: 10\n"
     ]
    }
   ],
   "source": [
    "data = dataset()\n",
    "print('Length:',len(data))\n",
    "print('10th element:',data[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can create an iterator for an iterable object using _iter_ built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iterator at 0x7f0aa82e9ac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can move the iterator to the next object using the _next_ built-in function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "it = iter(data)\n",
    "print(next(it), next(it), next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stochastic Batch-Data Using DataLoader\n",
    "Once we have an iterable data representation, the next step is to have a capability to create a randomly selected subset of data. Desired capabilities of this functionality includes also ability to choose random vs. ordered subset, parallelized workers to simultaneously prepare multiple batch data, and so on so forth.\n",
    "\n",
    "As this is a generic capability useful for _any_ data representation, Pytorch provide a generic API called **DataLoader**. Here is how one can instantiate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(data,batch_size=10,shuffle=True,num_workers=1,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataloader itself is an iterable object. We created a dataloader with batch size 10 where the dataset instance has the length 100. This means, if we iterate on the dataloader instance, we get 10 separate batch data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch entry 0 ... batch data tensor([ 7, 19, 95, 63, 17, 34, 68, 24, 55, 52])\n",
      "Batch entry 1 ... batch data tensor([ 3, 80, 60, 28, 23,  9, 29, 62, 94, 43])\n",
      "Batch entry 2 ... batch data tensor([53, 11, 61, 67, 42, 92, 37, 33, 88, 15])\n",
      "Batch entry 3 ... batch data tensor([22, 76, 20, 81, 36, 59, 41, 14, 72,  2])\n",
      "Batch entry 4 ... batch data tensor([89, 10,  4, 87, 79, 70, 75, 13, 21, 83])\n",
      "Batch entry 5 ... batch data tensor([35, 99, 84, 25, 32, 56, 49, 91, 30, 85])\n",
      "Batch entry 6 ... batch data tensor([96, 57, 47, 45, 65, 97, 27, 77, 69, 82])\n",
      "Batch entry 7 ... batch data tensor([ 8, 46,  6, 40, 39, 18, 86, 54, 73, 64])\n",
      "Batch entry 8 ... batch data tensor([90,  1, 44, 48, 38, 31,  5, 78, 16, 74])\n",
      "Batch entry 9 ... batch data tensor([58, 50, 98, 26, 66, 12, 51, 93, 71,  0])\n"
     ]
    }
   ],
   "source": [
    "for index, batch_data in enumerate(loader):\n",
    "    print('Batch entry',index,'... batch data',batch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that data elements are chosen randomly as we chose \"shuffle=True\". Does this cover all data elements in the dataset? Let's check this by combining all iterated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collection = []\n",
    "for index,batch_data in enumerate(loader):\n",
    "    data_collection += [int(v) for v in batch_data]\n",
    "    \n",
    "import numpy as np\n",
    "np.unique(data_collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
